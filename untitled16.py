# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1neWwr9ydur98TOXdQzT8-qNr78YSk_Os
"""

import numpy as np
import pandas as pd

# Read the CSV files
data = pd.read_csv('user_song.csv')
test_data = pd.read_csv('test.csv')

# Extract 'user_id', 'song_id', and 'weight' columns
test_user_ids = test_data['user_id']
test_song_ids = test_data['song_id']
train_user_ids = data['user_id']
train_song_ids = data['song_id']
weights = data['weight']

# Determine the number of unique user IDs and song IDs
unique_user_ids = sorted(set(train_user_ids.unique()).union(test_user_ids.unique()))
unique_song_ids = sorted(set(train_song_ids.unique()).union(test_song_ids.unique()))

# Determine the number of unique user IDs and song IDs
num_user_ids = len(unique_user_ids)
num_song_ids = len(unique_song_ids)

# Create a matrix of zeros
matrix = np.zeros((num_user_ids+1, num_song_ids+1), dtype=float)

# Assign unique user IDs to the first column
matrix[1:, 0] = unique_user_ids

# Assign unique song IDs to the first row
matrix[0, 1:] = unique_song_ids

# Iterate over each row in the CSV file
for row in data.itertuples(index=False):
    user_id = row.user_id
    song_id = row.song_id
    weight = row.weight
    # Find the indices of the user ID and song ID in the unique ID lists
    user_index = unique_user_ids.index(user_id) + 1
    song_index = unique_song_ids.index(song_id) + 1
    # Assign the weight value to the corresponding user-song combination
    matrix[user_index, song_index] = weight

# Create matrix R without the first row and first column
R = matrix[1:, 1:]

import numpy as np

# Get the number of non-zero values in matrix R
num_nonzero = np.count_nonzero(R)

# Calculate the average of non-zero values in matrix R
avg_nonzero = np.mean(R[R != 0])

# Create matrix A
num_rows_A = num_nonzero
num_cols_A = num_rows_A + R.shape[0] + R.shape[1]
A = np.zeros((num_rows_A, num_cols_A), dtype=int)

# Create vector c
c = np.zeros(num_rows_A)
nonzero_values = np.nonzero(R)

# Iterate over the non-zero values in matrix R
for i in range(num_nonzero):
    row = nonzero_values[0][i]
    col = nonzero_values[1][i]

    # Place 1 in the appropriate positions of matrix A
    A[i, row] = 1
    A[i, R.shape[0] + col] = 1

    # Calculate the value for vector c
    c[i] = R[row, col] - avg_nonzero

print(c)

k = 20
import numpy as np
from scipy.sparse.linalg import svds

# Perform sparse SVD on the sparse matrix R
u, s, vh = svds(R, k=k)

# Reconstruct the matrix using the truncated SVD components
res = u @ np.diag(s) @ vh
print(res)

# Step 1: Find the indices of non-zero values in matrix R
nonzero_indices = np.nonzero(R)

# Step 2: Retrieve the corresponding values from matrix R and matrix predicted
R_nonzero_values = R[nonzero_indices]
predicted_nonzero_values = res[nonzero_indices]

# Step 3: Calculate the squared difference between the values
squared_diff = (R_nonzero_values - predicted_nonzero_values) ** 2

# Step 4: Sum up the squared differences
sum_squared_diff = np.sum(squared_diff)

print("Sum of squared differences:", sum_squared_diff)

import pandas as pd

# Create a copy of the test data frame
data_updated = data.copy()



# Iterate over the rows in the test data frame
for row in data_updated.itertuples(index=False):
    user_id = row.user_id
    song_id = row.song_id

    # Find the corresponding indices in the matrix
    user_index = unique_user_ids.index(user_id)
    song_index = unique_song_ids.index(song_id)

    # Get the weight from the predict matrix
    weight = res[user_index, song_index]

    # Assign the weight to the test data frame
    data_updated.loc[(data_updated['user_id'] == user_id) & (data_updated['song_id'] == song_id), 'weight'] = weight

# Print the updated data frame
print(data_updated)
data_updated.to_csv('updated_data.csv', index=False)